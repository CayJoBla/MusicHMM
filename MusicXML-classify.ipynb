{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ae1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import music21\n",
    "import numpy as np\n",
    "import os\n",
    "import dill as pickle\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError as e:\n",
    "    print(e)\n",
    "    tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b8210",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8122f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Song class.\n",
    "        \n",
    "        Attributes:\n",
    "            score (Score): Song from music21 Score class\n",
    "            key (str): Key of the song\n",
    "            parts (ndarray(p,n)): Array of parts(p) and notes(n)\n",
    "            n_parts (int): Number of parts in the song\n",
    "            stream (Stream): music21 Stream object generated from parts\n",
    "        \"\"\"\n",
    "        return\n",
    "        \n",
    "    def parse(self, score):\n",
    "        \"\"\"Parse the MusicXML score into a trainable format\"\"\"\n",
    "        parts = []\n",
    "        discrete = [[]] * len(score.parts)\n",
    "        \n",
    "        # Generate discretized notelist for each part\n",
    "        for i, p in enumerate(score.parts):\n",
    "            for n in p.recurse().notesAndRests:\n",
    "                if n.isRest:\n",
    "                    discrete[i] = discrete[i] + ([0] * int(n.quarterLength*12))\n",
    "                else:\n",
    "                    discrete[i] = discrete[i] + ([n.pitch] * int(n.quarterLength*12))\n",
    "        #pad to make lengths the same\n",
    "        max_len = max([len(part) for part in discrete])\n",
    "        discrete = [\n",
    "            part + [part[-1]] * (max_len - len(part)) for part in discrete\n",
    "        ]\n",
    "        \n",
    "        discrete = np.array(discrete)\n",
    "        \n",
    "        # Generate states from the music\n",
    "        for i, p in enumerate(score.parts):\n",
    "            t = 0         # Time for dependence on other parts\n",
    "            notes = []    # States (pitch[0,t], ..., pitch[n_parts,t], dur)\n",
    "            for n in p.recurse().notesAndRests:\n",
    "                pitches = [part[t] for part in discrete]\n",
    "                notes.append(pitches + [n.quarterLength])\n",
    "                t += int(n.quarterLength*12)\n",
    "                \n",
    "            # Add notes list for each part to part list\n",
    "            parts.append(notes)  \n",
    "            \n",
    "        self.score = score\n",
    "        self.key = score.analyze('key')\n",
    "        self.parts = np.array(parts, dtype=object)\n",
    "        self.n_parts = len(parts)  \n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def gen_stream(self, parts=None):\n",
    "        \"\"\"Generate a song from the parts and notes parsed\n",
    "        \n",
    "        Parameters:\n",
    "            parts (list): list of part indices to generate\n",
    "        \"\"\"\n",
    "        # If None, generate all parts\n",
    "        if parts is None:\n",
    "            parts = np.arange(self.n_parts)\n",
    "        parts = np.array(parts, dtype=int)\n",
    "        \n",
    "        # Generate the song for the parts indicated\n",
    "        s = stream.Stream()\n",
    "        for i, notes in enumerate(self.parts[parts]):\n",
    "            p = stream.Part(id=i)\n",
    "            for n in notes: \n",
    "                if n[i] == 0:\n",
    "                    p.append(note.Rest(quarterLength=n[self.n_parts]))\n",
    "                else:\n",
    "                    p.append(note.Note(n[i],quarterLength=n[self.n_parts]))\n",
    "            s.insert(0,p)\n",
    "        self.stream = s\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def play(self):\n",
    "        \"\"\"Play the song generated by gen_stream\"\"\"\n",
    "        self.stream.show('midi')  \n",
    "        \n",
    "    def save(self, filename):\n",
    "        \"\"\"Save the generated song as a midi file\"\"\"\n",
    "        self.stream.write('midi')        # Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78488384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicHMM:\n",
    "    def __init__(self, n_components, reg_eps=0):\n",
    "        \"\"\"Initialize MusicHMM class\n",
    "        \n",
    "        Attributes:\n",
    "            songs (list): List of Song class objects to train on\n",
    "            n_components (int): number of components for the HMM\n",
    "            HMMs (list(MultinomialHMM)): HMM objects for each part\n",
    "            states (ndarray): Array of possible states\n",
    "            state_ind (func): Map from note state to index\n",
    "            obs (list): Observed sequences of states by index\n",
    "            obs_len (list): length of observation sequence for each song\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.reg_eps = reg_eps\n",
    "        \n",
    "    def fit(self, songs, parts=[0,1,2,3]):\n",
    "        \"\"\"Train the HMM on the list of songs for part indices given\n",
    "        \n",
    "        Parameters:\n",
    "            songs (list): List of parsed Song objects to train on\n",
    "            parts (list): List of part indices from songs to use in training\n",
    "        \"\"\"\n",
    "        self.songs = songs\n",
    "        \n",
    "        # Generate state space data and observations by index\n",
    "        self.init_states(parts)\n",
    "        self.init_obs_matrices(parts)\n",
    "        \n",
    "        # Train a HMM for each part\n",
    "        n_parts = len(parts)\n",
    "        n_features = len(self.states)\n",
    "        HMMs = []\n",
    "        for i in range(n_parts):\n",
    "            obs = np.array(self.obs[i]).reshape(-1, 1)   # Reshape observations\n",
    "            hmm = MultinomialHMM(n_components=self.n_components)\n",
    "            hmm.n_features = n_features\n",
    "            hmm.fit(obs, lengths=self.obs_len[i])\n",
    "            if self.reg_eps != 0:\n",
    "                hmm.emissionprob_ = hmm.emissionprob_* (1-hmm.emissionprob_.shape[1] * self.reg_eps / n_features)\\\n",
    "                                    + self.reg_eps/n_features\n",
    "            HMMs.append(hmm)\n",
    "            \n",
    "        self.HMMs = HMMs\n",
    "        self.n_parts = len(parts)\n",
    "        self.parts = parts\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def init_states(self, parts):\n",
    "        \"\"\"Create and save a dictionary of unique note states\"\"\"\n",
    "        states = {tuple(n) for song in self.songs for p in song.parts[parts] for n in p}\n",
    "                    \n",
    "        self.states = list(states)\n",
    "        self.states_dict = {n:i for i,n in enumerate(self.states)}\n",
    "        # Add a observation state for when we don't recognize the input\n",
    "        self.state_ind = lambda n: self.states_dict.get(tuple(n), self.missing_state_id)\n",
    "        self.missing_state_id = len(self.states)\n",
    "        self.states.append(self.states[0])\n",
    "        self.states = np.array(self.states)\n",
    "        \n",
    "    def init_obs_matrices(self, parts):\n",
    "        \"\"\"Create the matrices of note indices observed\"\"\"\n",
    "        # Initialize\n",
    "        n_parts = len(parts)\n",
    "        obs = [[]] * n_parts\n",
    "        obs_len = [[]] * n_parts\n",
    "        \n",
    "        for i in range(n_parts):\n",
    "            for song in self.songs:\n",
    "                p = song.parts[parts[i]]\n",
    "                seq = [self.state_ind(n) for n in p]\n",
    "                obs[i] += seq                                     ###########################\n",
    "                obs_len[i].append(len(seq))\n",
    "                \n",
    "        self.obs = obs\n",
    "        self.obs_len = obs_len \n",
    "                \n",
    "               \n",
    "    def gen_song(self, num_notes=40):\n",
    "        \"\"\"Sample a new song from the HMM\n",
    "        \n",
    "        Parameters:\n",
    "            num_notes (int): Number of notes to sample from each part\n",
    "            parts (list): List of part indices to generate in song\n",
    "        \"\"\"\n",
    "        s = stream.Score()\n",
    "        part_lengths = []\n",
    "        for i in range(self.n_parts):\n",
    "            hmm = self.HMMs[i]\n",
    "            ind = hmm.sample(num_notes)[0].ravel()\n",
    "            states = self.states[ind]\n",
    "            T = 0\n",
    "            \n",
    "            p = stream.Part(id=i)\n",
    "            for n in states: \n",
    "                if n[i] == 0:\n",
    "                    p.append(note.Rest(quarterLength=n[self.n_parts]))\n",
    "                else:\n",
    "                    p.append(note.Note(n[i],quarterLength=n[self.n_parts]))\n",
    "                T += n[self.n_parts]\n",
    "            s.insert(0,p)\n",
    "            part_lengths.append(T)\n",
    "        \n",
    "        max_len = max(part_lengths)    \n",
    "        for i, p in enumerate(s.parts):\n",
    "            if part_lengths[i] < max_len:\n",
    "                p.append(note.Rest(quarterLength=max_len-part_lengths[i]))\n",
    "            \n",
    "        new_song = Song()\n",
    "        new_song.parse(s)\n",
    "        new_song.gen_stream()\n",
    "        \n",
    "        return new_song\n",
    "    \n",
    "    def predict_proba(self, songs):\n",
    "        \"\"\"Returns the log-likelihood of each song given the model\"\"\"\n",
    "        if issubclass(songs.__class__, Song):\n",
    "            songs = [songs]\n",
    "        songs = np.array(songs, dtype=object)\n",
    "        \n",
    "        return np.array([self.predict_proba_single(song) for song in songs])\n",
    "        \n",
    "    def predict_proba_single(self, song):\n",
    "        log_likelihood = 0.\n",
    "        n_parts = len(self.parts)\n",
    "        return np.sum([hmm.score(self._get_obs(song, self.parts[i])) for i, hmm in enumerate(self.HMMs)])\n",
    "        \"\"\"for i, hmm in enumerate(self.HMMs):\n",
    "            obs = self._get_obs(song, self.parts[i])\n",
    "            log_likelihood += hmm.score(obs)\n",
    "        return log_likelihood\"\"\"\n",
    "    \n",
    "    def _get_obs(self, song, part):\n",
    "        p = song.parts[self.parts[part]]\n",
    "        return np.array([self.state_ind(n) for n in p]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ade40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicHMMClassifier:\n",
    "    \"\"\"\n",
    "    Class for classifying music by composer using HMMs. The predictions are made based on maximum log-likelihood.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components, parts=[0,1,2,3], reg_eps=1e-2):\n",
    "        self.labels = []\n",
    "        self.hmms_maj = []\n",
    "        self.hmms_min = []\n",
    "        \n",
    "        self.n_components = n_components\n",
    "        self.parts = parts\n",
    "        self.reg_eps = reg_eps\n",
    "        \n",
    "    def fit_items(self, *args):\n",
    "        \"\"\"\n",
    "        Fits the classifiers, where each argument is a tuple of (composer name, [list of Maj songs], [list of Min songs])\n",
    "        \"\"\"\n",
    "        # Train on the given classifiers\n",
    "        for composer, X_maj, X_min in args:\n",
    "            if composer in self.labels:\n",
    "                continue\n",
    "            else:\n",
    "                idx = len(self.labels)\n",
    "                self.labels.append(composer)\n",
    "            # Train models for major and minor pieces\n",
    "            if len(X_maj) > 0:\n",
    "                self.hmms_maj.append(MusicHMM(self.n_components, reg_eps=self.reg_eps).fit(X_maj, parts=self.parts))\n",
    "            else:\n",
    "                self.hmms_maj.append(None)\n",
    "            if len(X_min) > 0:\n",
    "                self.hmms_min.append(MusicHMM(self.n_components, reg_eps=self.reg_eps).fit(X_min, parts=self.parts))\n",
    "            else:\n",
    "                self.hmms_min.append(None)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def fit(X, y, labels=None):\n",
    "        \"\"\"\n",
    "        Fits the classifiers.\n",
    "        \"\"\"\n",
    "        X_maj, X_min = X\n",
    "        y_maj, y_min = y\n",
    "        # cast as arrays\n",
    "        y_maj = np.array(y_maj)\n",
    "        y_min = np.array(y_min)\n",
    "        X_maj = np.array(X_maj)\n",
    "        X_min = np.array(X_min)\n",
    "        \n",
    "        if labels is None:\n",
    "            labels = np.unique(y)\n",
    "        \n",
    "        masks = [(y_maj == l, y_min == l) for l in labels]\n",
    "        self.fit_items(*[(l, X_maj[m_maj], X_min[m_min]) for l, (m_maj, m_min) in zip(labels, masks)])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _major_likelihood(self, song):\n",
    "        return [\n",
    "            mhmm.predict_proba_single(song) for mhmm in self.hmms_maj\n",
    "        ]\n",
    "    \n",
    "    def _minor_likelihood(self, song):\n",
    "        return [\n",
    "            mhmm.predict_proba_single(song) for mhmm in self.hmms_min\n",
    "        ]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Returns the log-likelihood of each song given each model.\n",
    "        This will be a (n, H) array, where n is the number of songs provided and H is the number of composers known to this model.\n",
    "        \"\"\"\n",
    "        songs = X\n",
    "        if issubclass(songs.__class__, Song):\n",
    "            songs = [songs]\n",
    "        \n",
    "        # Predictions are separate for major/minor key songs\n",
    "        is_maj = ['major' in song.key.name for song in songs]\n",
    "        \n",
    "        likelihoods = np.array([\n",
    "            self._major_likelihood(song) if maj else self._minor_likelihood(song) for song, maj in zip(songs, is_maj)\n",
    "        ])\n",
    "        return likelihoods\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the labels for each \"\"\"\n",
    "        likelihood = self.predict_proba(X)\n",
    "        label_indices = np.argmax(likelihood, axis=1)\n",
    "        return np.array(self.labels, dtype=object)[label_indices]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadfb975",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bb0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_split(composer_name, train_prop=0.6, seed=None, accept=lambda p: len(p.parts)==4):\n",
    "    \"\"\"\n",
    "    Loads the corpus, filter to songs with 4 parts, transposes to C, splits into major and minor, splits into train/test.\n",
    "    train_prop can be either a proportion or a fixed numer.\n",
    "    \n",
    "    Returns:\n",
    "        (major, minor) - tuple of training data\n",
    "        (major, minor) - tuple of test data\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    paths = corpus.getComposer(composer_name)\n",
    "    transposed_major = []\n",
    "    transposed_minor = []\n",
    "    # Load songs\n",
    "    for p_name in tqdm(paths):\n",
    "        p = corpus.parse(p_name)\n",
    "        if not accept(p):\n",
    "            continue\n",
    "        k = p.analyze('key')\n",
    "        i = interval.Interval(k.tonic, pitch.Pitch('C'))\n",
    "        song = Song().parse(p.transpose(i)).gen_stream()\n",
    "        if 'major' in k.name:\n",
    "            transposed_major.append(song)\n",
    "        elif 'minor' in k.name:\n",
    "            transposed_minor.append(song)\n",
    "    # Train/test split\n",
    "    def split(l):\n",
    "        \"\"\"Splits the list into train and test portions\"\"\"\n",
    "        l = np.array(l, dtype=object)\n",
    "        if int(train_prop) == train_prop:\n",
    "            num = train_prop\n",
    "        else:\n",
    "            num = int(len(l) * train_prop)\n",
    "        # Select which ones to use\n",
    "        idx = rng.choice(len(l), size=num, replace=False).astype(int)\n",
    "        mask = np.full_like(l, False, dtype=bool)\n",
    "        mask[idx] = True\n",
    "        return l[mask], l[~mask]\n",
    "        \n",
    "    maj_tr, maj_test = split(transposed_major)\n",
    "    min_tr, min_test = split(transposed_minor)\n",
    "    \n",
    "    return (maj_tr, min_tr), (maj_test, min_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c7faf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf91f725ab594402842316a1529ea169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bd764ac3a04d0f9877dbe1618708a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This takes about 20 minutes to run\n",
    "bach_train, bach_test = load_clean_split('bach', train_prop=50)\n",
    "pal_train, pal_test = load_clean_split('palestrina', train_prop=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e726ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "print(np.sum((bach_train[0].shape, bach_test[0].shape, bach_train[1].shape, bach_test[1].shape)))\n",
    "print(np.sum((pal_train[0].shape, pal_test[0].shape, pal_train[1].shape, pal_test[1].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60808334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (132,) (50,) (136,)\n",
      "(50,) (180,) (50,) (218,)\n"
     ]
    }
   ],
   "source": [
    "print(bach_train[0].shape, bach_test[0].shape, bach_train[1].shape, bach_test[1].shape)\n",
    "print(pal_train[0].shape, pal_test[0].shape, pal_train[1].shape, pal_test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77d50249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split into a validation set\n",
    "val_size = 50\n",
    "bach_fulltest = bach_test\n",
    "pal_fulltest = pal_test\n",
    "np.random.shuffle(bach_fulltest[0])\n",
    "np.random.shuffle(bach_fulltest[1])\n",
    "np.random.shuffle(pal_fulltest[0])\n",
    "np.random.shuffle(pal_fulltest[1])\n",
    "bach_val_maj, bach_test_maj = bach_fulltest[0][:val_size], bach_fulltest[0][val_size:]\n",
    "bach_val_min, bach_test_min = bach_fulltest[1][:val_size], bach_fulltest[1][val_size:]\n",
    "pal_val_maj, pal_test_maj = pal_fulltest[0][:val_size], pal_fulltest[0][val_size:]\n",
    "pal_val_min, pal_test_min = pal_fulltest[1][:val_size], pal_fulltest[1][val_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283e9c1",
   "metadata": {},
   "source": [
    "# Testing a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00aaf1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 25659 free scalar parameters with only 11778 data points will result in a degenerate solution.\n",
      "Fitting a model with 25659 free scalar parameters with only 11778 data points will result in a degenerate solution.\n",
      "Fitting a model with 25659 free scalar parameters with only 11778 data points will result in a degenerate solution.\n",
      "Fitting a model with 25659 free scalar parameters with only 11778 data points will result in a degenerate solution.\n",
      "Fitting a model with 27659 free scalar parameters with only 12471 data points will result in a degenerate solution.\n",
      "Fitting a model with 27659 free scalar parameters with only 12471 data points will result in a degenerate solution.\n",
      "Fitting a model with 27659 free scalar parameters with only 12471 data points will result in a degenerate solution.\n",
      "Fitting a model with 27659 free scalar parameters with only 12471 data points will result in a degenerate solution.\n",
      "Fitting a model with 93299 free scalar parameters with only 27292 data points will result in a degenerate solution.\n",
      "Fitting a model with 93299 free scalar parameters with only 27292 data points will result in a degenerate solution.\n",
      "Fitting a model with 93299 free scalar parameters with only 27292 data points will result in a degenerate solution.\n",
      "Fitting a model with 93299 free scalar parameters with only 27292 data points will result in a degenerate solution.\n",
      "Fitting a model with 86939 free scalar parameters with only 25589 data points will result in a degenerate solution.\n",
      "Fitting a model with 86939 free scalar parameters with only 25589 data points will result in a degenerate solution.\n",
      "Fitting a model with 86939 free scalar parameters with only 25589 data points will result in a degenerate solution.\n",
      "Fitting a model with 86939 free scalar parameters with only 25589 data points will result in a degenerate solution.\n"
     ]
    }
   ],
   "source": [
    "n_states = 10\n",
    "mhmm_classifier = MusicHMMClassifier(n_states, parts=[0,1,2,3]).fit_items(\n",
    "    ('bach', *bach_train),\n",
    "    ('palestrina', *pal_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e916c02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Validation set results ====\n",
      "Accuracy on major-key Bach songs: 1.000000\n",
      "Accuracy on minor-key Bach songs: 1.000000\n",
      "Accuracy on major-key Palestrina songs: 0.980000\n",
      "Accuracy on minor-key Palestrina songs: 0.980000\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*4+\" Validation set results \"+'='*4)\n",
    "print('Accuracy on major-key Bach songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(bach_val_maj) == 'bach')))\n",
    "print('Accuracy on minor-key Bach songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(bach_val_min) == 'bach')))\n",
    "print('Accuracy on major-key Palestrina songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(pal_val_maj) == 'palestrina')))\n",
    "print('Accuracy on minor-key Palestrina songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(pal_val_min) == 'palestrina')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32877ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Test set results ====\n",
      "Accuracy on major-key Bach songs: 1.000000\n",
      "Accuracy on minor-key Bach songs: 1.000000\n",
      "Accuracy on major-key Palestrina songs: 0.992308\n",
      "Accuracy on minor-key Palestrina songs: 0.970238\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*4+\" Test set results \"+'='*4)\n",
    "print('Accuracy on major-key Bach songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(bach_test_maj) == 'bach')))\n",
    "print('Accuracy on minor-key Bach songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(bach_test_min) == 'bach')))\n",
    "print('Accuracy on major-key Palestrina songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(pal_test_maj) == 'palestrina')))\n",
    "print('Accuracy on minor-key Palestrina songs: {:.6f}'.format(np.mean(mhmm_classifier.predict(pal_test_min) == 'palestrina')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4187f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b374e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39aee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c8806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
